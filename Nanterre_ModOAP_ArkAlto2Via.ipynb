{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModOAP_ArksAlto2Via.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNhDNHVVBPSe"
      },
      "source": [
        "# ModOAP - Extraction des annotations de régions d'illustration dans des documents Gallica\n",
        "\n",
        "Ce script permet de récupérer les annotations des régions représentant des illustrations dans des pages de documents historiques stockés sur Gallica.\n",
        "\n",
        "A partir de liens ARK contenus dans un fichier excel, le script télécharge pour chaque document les pages qu'il contient, et génère un fichier d'annotation VIA (format json) contenant les régions des illustrations des documents. \n",
        "\n",
        "Le dossier téléchargé par ce script peut ensuite être directement utilisé pour l'entraînement d'un algorithme de détection d'illustrations. \n",
        "\n",
        "**Fonctionnement :** \n",
        "\n",
        "- Synchroniser un compte Google Drive\n",
        "- Spécifier un fichier XLS dont une colonne contient des liens vers des documents Gallica (ex : https://gallica.bnf.fr/ark:/12148/bpt6k54715050)\n",
        "- Spécifier l'index de la colonne contenant ces liens\n",
        "- Spécifier un dossier de destination où télécharger les documents\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11aEGN4-80Vp",
        "cellView": "form"
      },
      "source": [
        "#@title ##  Préparation\n",
        "\n",
        "#@markdown ### Synchronisation d'un Google Drive\n",
        "#@markdown ##### Lancer cette cellule et cliquer sur le lien généré pour autoriser un compte Google Drive\n",
        "\n",
        "try :\n",
        "    import xmltodict\n",
        "except ModuleNotFoundError :\n",
        "    !pip install xmltodict\n",
        "import shutil\n",
        "import requests\n",
        "import xmltodict\n",
        "from bs4 import BeautifulSoup\n",
        "from openpyxl import load_workbook\n",
        "import urllib.request, urllib.error, urllib.parse\n",
        "from urllib.error import HTTPError, URLError\n",
        "from xml.etree import ElementTree as ET\n",
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "\n",
        "# chargement d'un google drive\n",
        "if not os.path.exists(\"/content/drive/MyDrive/\") :\n",
        "    drive.mount('/content/drive/')\n",
        "\n",
        "\"\"\"if not os.path.exists(\"/content/drive/MyDrive/Outils_Modoap/Scrap\"):\n",
        "    os.makedirs(\"/content/drive/MyDrive/Outils_Modoap/Scrap\")    \n",
        "\n",
        "%cd /content/drive/MyDrive/Outils_Modoap/Scrap\"\"\"\n",
        "\n",
        "# définition des fonctions\n",
        "def paginationDL(ark):\n",
        "    try :\n",
        "        PAGINATION_BASEURL = 'https://gallica.bnf.fr/services/Pagination?ark='\n",
        "        url = \"\".join([PAGINATION_BASEURL, ark])\n",
        "        s = requests.get(url, stream=True)\n",
        "        pagination = str(BeautifulSoup(s.content,\"lxml-xml\"))\n",
        "        paginationdic = xmltodict.parse(pagination)\n",
        "        nb_pages = int(paginationdic[\"livre\"][\"structure\"][\"nbVueImages\"])\n",
        "        with open(\"pagination_\"+str(ark), \"w\") as pagout :\n",
        "            pagout.write(pagination)\n",
        "        return paginationdic, nb_pages\n",
        "    except :\n",
        "        print(\"la pagination n'a pas été téléchargée\")\n",
        "        \n",
        "\n",
        "def altoDL(ark,page, ordre, numero):\n",
        "    \n",
        "    OCR_BASEURL = 'https://gallica.bnf.fr/RequestDigitalElement?O='\n",
        "    url = \"\".join([OCR_BASEURL, ark, '&E=ALTO&Deb=', str(page)])\n",
        "    s = requests.get(url, stream=True)\n",
        "    alto = str(BeautifulSoup(s.content,\"lxml-xml\"))\n",
        "    nomfichier = \"view_\"+str(ordre)+\"_num_\"+str(numero)+\"_alto.xml\"\n",
        "    with open(nomfichier, \"w\") as altout :\n",
        "        altout.write(alto)\n",
        "    if len(alto) < 40 :\n",
        "        return \"no\", nomfichier\n",
        "    else :\n",
        "        return \"yes\", nomfichier\n",
        "\n",
        "def nb_pages(manifeste) : \n",
        "    with open(manifeste) as f:\n",
        "        dico = json.load(f)\n",
        "    nb_pages = len(dico[\"sequences\"][0][\"canvases\"])\n",
        "    return nb_pages\n",
        "\n",
        "def manifesteDL(ark):\n",
        "    try :\n",
        "        url = \"https://gallica.bnf.fr/iiif/ark:/12148/\"+str(ark)+\"/manifest.json\"\n",
        "        nom_fichier = ark+\"-manifest.json\"\n",
        "        urllib.request.urlretrieve(url, nom_fichier)\n",
        "        return nom_fichier\n",
        "    except :\n",
        "        print(\"Le manifeste n'a pas pu être téléchargé\")\n",
        "\n",
        "def pageDL(ark, page, numero_page, numero_phys, region=\"full\", size=\"full\", rotation=\"0\", quality=\"native\", format=\"jpg\"):\n",
        "    IIIF_BASEURL = 'https://gallica.bnf.fr/iiif/ark:/12148/'\n",
        "    url = \"\".join([IIIF_BASEURL, ark, '/f', str(page), '/', region, '/', size, '/', rotation, '/', quality, '.', format])\n",
        "    nom_fichier = ark+\"_view_\"+str(ordre)+\"_num_\"+str(numero)+\".jpg\"\n",
        "    try :\n",
        "        urllib.request.urlretrieve(url, nom_fichier)\n",
        "        return \"ok\"\n",
        "    except (HTTPError, URLError) as erreur:\n",
        "        return str(erreur.reason)        \n",
        "\n",
        "def bnf2gall(arkbnf):\n",
        "    url = \"https://catalogue.bnf.fr/ark:/12148/\"+str(arkbnf)\n",
        "    s = requests.get(url, stream=True)\n",
        "    html = BeautifulSoup(s.content,\"lxml-xml\")\n",
        "    for link in html.findAll('a', {'class': 'exemplaire-action-visualiser'}):\n",
        "        ark = link['href'].split(\"/\")[-1]\n",
        "        return ark\n",
        "\n",
        "\n",
        "def page_courante(ark, page, pagination):\n",
        "    ordre = pagination[\"livre\"][\"pages\"][\"page\"][int(page-1)][\"ordre\"]\n",
        "    numero = pagination[\"livre\"][\"pages\"][\"page\"][int(page-1)][\"numero\"]\n",
        "    return ordre, numero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0df0QwGS9OW5",
        "cellView": "form"
      },
      "source": [
        "# Récupération des liens depuis le fichier xls\n",
        "\n",
        "#@title ## 0. Préparation\n",
        "\n",
        "#@markdown ### Entrez le chemin du fichier xls :\n",
        "chemin_fichier_xls = \"/content/drive/MyDrive/Outils_Modoap/Scrap/excels/test2.xlsx\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Possibilité de copier/coller le chemin depuis la fenêtre de gauche : onglet \"Fichiers\" -> clic droit sur un dossier -> \"Copier le chemin\"\n",
        "\n",
        "#@markdown Exemple de chemin:\n",
        "#@markdown /content/drive/My Drive/fichiers/\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown ### Entrez l'indice de la colonne contenant les liens ARK :\n",
        "colonne_ark = \"A\" #@param {type:\"string\"}\n",
        "#@markdown Exemple d'indice : A\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown ### Entrez le répertoire de destination où télécharger les documents :\n",
        "chemin_destination = \"/content/drive/MyDrive/Outils_Modoap/Scrap/test3\" #@param {type:\"string\"}\n",
        "#@markdown Exemple de chemin:\n",
        "#@markdown /content/drive/My Drive/datasets/\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "chemin_classeur = chemin_fichier_xls\n",
        "\n",
        "try :\n",
        "  if not os.path.exists(chemin_destination):\n",
        "      os.makedirs(chemin_destination)\n",
        "except :\n",
        "  print(\"Le chemin de destination est incorrect\")\n",
        "\n",
        "arks = []\n",
        "\n",
        "# Chargement du fichier xls\n",
        "try :\n",
        "  classeur= load_workbook(chemin_classeur)\n",
        "except :\n",
        "  print(\"Le fichier xls n'a pas été chargé correctement\")\n",
        "\n",
        "# Récupération des liens ARK\n",
        "for onglet in classeur.sheetnames:\n",
        "    onglet_courant = classeur[onglet]\n",
        "    colonne = onglet_courant[colonne_ark]\n",
        "    for cellule in colonne :\n",
        "        if str(cellule.value).startswith(\"http\") or str(cellule.value).startswith(\"ark\"):\n",
        "            arks.append(str(cellule.value))\n",
        "\n",
        "arks = set(arks)\n",
        "print(\"{0} liens distincts récupérés dans {1} onglets\".format(len(arks), len(classeur.sheetnames)))\n",
        "\n",
        "# Tri des liens Gallica\n",
        "arks_gallica = []\n",
        "arks_autres_serveurs = []\n",
        "\n",
        "for ark in arks :\n",
        "  \n",
        "  if ark.endswith(\"/\") :\n",
        "    ark = ark[:-1]\n",
        "  ark2 = ark.split(\"/\")[-1].strip()\n",
        "  print(\"ark2 : \", ark2)\n",
        "  if \"?\" in ark2 :\n",
        "    ark2 = str(ark2.split(\"?\")[0])\n",
        "  if ark2.endswith(\"item\") :\n",
        "    ark2 = ark.split(\"/\")[-2]\n",
        "  if ark2.startswith(\"b\") :\n",
        "    arks_gallica.append(ark2)\n",
        "  elif ark2.startswith(\"c\") :\n",
        "    ark2 = bnf2gall(ark2)\n",
        "    arks_gallica.append(ark2)\n",
        "  else : \n",
        "    arks_autres_serveurs.append(ark2)\n",
        "\n",
        "print(\"{0} liens Gallica et {1} sur d'autres serveurs\".format(len(arks_gallica), len(arks_autres_serveurs)))\n",
        "\n",
        "%cd $chemin_destination\n",
        "\n",
        "\n",
        "erreurs_500 = []\n",
        "sans_ocr = []\n",
        "\n",
        "if len(arks_gallica) > 0 :\n",
        "  for ark in arks_gallica :\n",
        "    fichiers_telecharges = [fich.split(\"/\")[-1] for fich in glob.glob(os.path.join(chemin_destination,\"*.*\"))]\n",
        "    \n",
        "    print(\"Ark : \", ark)\n",
        "   \n",
        "    # Téléchargement du fichier de pagination\n",
        "    pagination, nb_pages = paginationDL(ark)\n",
        "    print(\"Nombre de pages : \", str(nb_pages))\n",
        "    for page in range(nb_pages) :\n",
        "      page += 1\n",
        "      print(\"Page {0}/{1}\".format(str(page), str(nb_pages)))\n",
        "      ordre, numero = page_courante(ark, page, pagination)\n",
        "    \n",
        "    # Téléchargement du fichier alto\n",
        "      if \"view_\"+str(ordre)+\"_num_\"+str(numero)+\"_alto.xml\" in fichiers_telecharges :\n",
        "        print(\"Fichier Alto déjà téléchargé\")\n",
        "      else :\n",
        "        reponse_alto, nomfichier = altoDL(ark,page, ordre, numero)\n",
        "        if reponse_alto ==\"yes\" :\n",
        "          # Récupération des régions\n",
        "          ###################################################\n",
        "          with open(nomfichier, \"r\") as fichalto :\n",
        "            alto = fichalto.read()\n",
        "    \n",
        "          altodic = xmltodict.parse(alto)\n",
        "          illustrations = []\n",
        "\n",
        "          try :\n",
        "            element = altodic[\"alto\"][\"Layout\"][\"Page\"][\"PrintSpace\"][\"Illustration\"]\n",
        "            if isinstance(element, list) :\n",
        "              for e in element :\n",
        "                illustrations.append(e)\n",
        "            else : \n",
        "                illustrations.append(element)\n",
        "          except KeyError :\n",
        "            pass\n",
        "\n",
        "          try :\n",
        "            if isinstance(altodic[\"alto\"][\"Layout\"][\"Page\"][\"PrintSpace\"][\"ComposedBlock\"], dict):\n",
        "\n",
        "\n",
        "              element = altodic[\"alto\"][\"Layout\"][\"Page\"][\"PrintSpace\"][\"ComposedBlock\"][\"Illustration\"]\n",
        "              if isinstance(element, list) :\n",
        "                for e in element :\n",
        "                  illustrations.append(e)\n",
        "              else : \n",
        "                  illustrations.append(element)\n",
        "      \n",
        "            elif isinstance(altodic[\"alto\"][\"Layout\"][\"Page\"][\"PrintSpace\"][\"ComposedBlock\"], list):\n",
        "              for element in altodic[\"alto\"][\"Layout\"][\"Page\"][\"PrintSpace\"][\"ComposedBlock\"] :\n",
        "                if \"Illustration\" in element :\n",
        "                  if isinstance(element, list) :\n",
        "                    for e in element :\n",
        "                      illustrations.append(e)\n",
        "                  else : \n",
        "                    illustrations.append(element)\n",
        "\n",
        "          except : pass\n",
        "          liste_regions = []\n",
        "          for illustration in illustrations : \n",
        "            hpos = int(illustration[\"@HPOS\"])\n",
        "            vpos = int(illustration[\"@VPOS\"])\n",
        "            width = int(illustration[\"@WIDTH\"])\n",
        "            height = int(illustration[\"@HEIGHT\"])\n",
        "            dico_reg_att = {\"type\" : \"illustration\"}\n",
        "            dico_shape_att = {\"all_points_x\" : [hpos, hpos+width, hpos+width, hpos] , \"all_points_y\" : [vpos, vpos, vpos+height, vpos+height], \"name\" : \"polygon\"}\n",
        "            dico_region = {\"region_attributes\" : dico_reg_att , \"shape_attributes\" : dico_shape_att }\n",
        "            liste_regions.append(dico_region)\n",
        "\n",
        "          dicofichier = {\"filename\" : ark+\"_view_\"+str(ordre)+\"_num_\"+str(numero)+\".jpg\", \"regions\" : liste_regions }\n",
        "          dico_illustrations_fichier = {ark+\"_view_\"+str(ordre)+\"_num_\"+str(numero)+\".jpg\" : dicofichier}\n",
        "\n",
        "          try : \n",
        "            with open(\"via_annotations.json\", \"r\") as jjson :\n",
        "              temp = jjson.read()\n",
        "              dicototal = json.loads(temp)\n",
        "          except FileNotFoundError:\n",
        "            dicototal = {}\n",
        "          dicototal[nomfichier] = dicofichier\n",
        "          with open(\"via_annotations.json\", \"w\") as jjson :\n",
        "            json.dump(dicototal, jjson)\n",
        "\n",
        "        if reponse_alto == \"no\" :\n",
        "          sans_ocr.append(ark)\n",
        "          print(\"ocr indisponible\")\n",
        "        ###################################################\n",
        "  \n",
        "\n",
        "    # Téléchargement de l'image de la page'\n",
        "      \n",
        "      if ark+\"_view_\"+str(ordre)+\"_num_\"+str(numero)+\".jpg\" in fichiers_telecharges :\n",
        "        print(\"Fichier Image déjà téléchargé\")\n",
        "      else :\n",
        "        reponse_doc = pageDL(ark, page, ordre, numero)\n",
        "        if reponse_doc == \"ok\" :\n",
        "          pass\n",
        "        if reponse_doc == \"500\" :\n",
        "          erreurs_500.append(ark)\n",
        "          print(\"erreur 500\")\n",
        "          break\n",
        "        else : pass \n",
        "        \n",
        "for fichier in glob.glob(os.path.join(chemin_destination,\"*.xml\")) :\n",
        "  os.remove(fichier)\n",
        "for fichier in glob.glob(os.path.join(chemin_destination,\"*\")) :\n",
        "  if \"pagination\" in fichier : \n",
        "    os.remove(fichier)\n",
        "\n",
        "erreurs_500 = set(erreurs_500)\n",
        "with open(\"erreurs_500.txt\", \"w\") as err :\n",
        "  err.write(\"=============================\")\n",
        "  err.write(\"Erreurs 500 : \")\n",
        "  err.write(\"=============================\")\n",
        "  for ark in erreurs_500 :\n",
        "    err.write(ark)\n",
        "    err.write(\"\\n\")\n",
        "  err.write(\"=============================\")\n",
        "  err.write(\"Documents non-océrisés : \")\n",
        "  err.write(\"=============================\")\n",
        "  for ocrless in sans_ocr :\n",
        "    err.write(ocrless)\n",
        "  \n",
        "  \n",
        "print(\"Documents non téléchargés (erreur 500) : {0}\".format(len(erreurs_500)))\n",
        "print(\"Ces documents sont listés dans le fichier erreurs_500.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}